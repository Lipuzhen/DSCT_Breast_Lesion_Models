"""
MODULE 1 – Minimal invasive Scheme B
FINAL INTEGRATED VERSION (CLEAN & SAFE)

Outputs:
- Table 2 (Clinical characteristics)
- Table 3 (DSCT parameters: AP + VP, journal format)
- Table S2–S4 (Univariable ROC)
- ROC curves for clinical / AP / VP
- sig_clinical / sig_dsct for MODULE 2
"""

import os
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve

# ======================================================
# Config
# ======================================================
DATA_PATH = r"E:\newdata11.xlsx"
OUTPUT_DIR = r"E:\DSCT_final_pipeline20"
os.makedirs(OUTPUT_DIR, exist_ok=True)

RANDOM_STATE = 2025
np.random.seed(RANDOM_STATE)

TARGET_COL = "Breast lesion"

# ======================================================
# 0. Load data & clean columns
# ======================================================
df_raw = pd.read_excel(DATA_PATH)
df_raw = df_raw.rename(columns={"Tumor size": "Tumor size (mm)"})
df_raw.columns = [c.strip() for c in df_raw.columns]

clinical_features = [
    "Age", "Menstruation status", "Childbearing history", "FGT",
    "Location", "Focality", "Calcification", "Tumor size (mm)",
    "Shape", "Margin", "Enhancement degree", "Enhancement pattern",
]

arterial_vars = [
    "A40", "A70", "AλHU", "A100",
    "AIC", "AZeff", "ANIC", "ANZeff"
]

venous_vars = [
    "V40", "V70", "VλHU", "V100",
    "VIC", "VZeff", "VNIC", "VNZeff"
]

dsct_features = arterial_vars + venous_vars

required_cols = [TARGET_COL] + clinical_features + dsct_features
missing = [c for c in required_cols if c not in df_raw.columns]
if missing:
    raise ValueError(f"Missing columns: {missing}")

df = df_raw[required_cols].copy()
y_all = df[TARGET_COL].astype(int)
X_all = df.drop(columns=[TARGET_COL])

# ======================================================
# 1. Train / Val / Test split
# ======================================================
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.16,
    stratify=y_all,
    random_state=RANDOM_STATE
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=0.175,
    stratify=y_train_val,
    random_state=RANDOM_STATE
)

for obj in [X_train, X_val, X_test, y_train, y_val, y_test]:
    obj.reset_index(drop=True, inplace=True)

# ======================================================
# 2. Continuous variable test (Scheme B)
# ======================================================
def auto_test_continuous(x0, x1):
    x0, x1 = x0.dropna(), x1.dropna()
    if len(x0) < 3 or len(x1) < 3:
        return 1.0
    normal = (
        stats.shapiro(x0)[1] >= 0.05 and
        stats.shapiro(x1)[1] >= 0.05
    )
    if normal:
        if stats.levene(x0, x1)[1] >= 0.05:
            _, p = stats.ttest_ind(x0, x1, equal_var=True)
        else:
            _, p = stats.ttest_ind(x0, x1, equal_var=False)
    else:
        _, p = stats.mannwhitneyu(x0, x1, alternative="two-sided")
    return p

# ======================================================
# 3. Univariate analysis (TRAIN only)
# ======================================================
clinical_categorical = {
    "Menstruation status", "Childbearing history", "FGT",
    "Location", "Focality", "Calcification",
    "Shape", "Margin", "Enhancement degree", "Enhancement pattern"
}

def univariate_analysis_train(X, y):
    rows = []
    for col in clinical_features + dsct_features:
        x0 = X.loc[y == 0, col]
        x1 = X.loc[y == 1, col]
        if col in clinical_categorical:
            tab = pd.crosstab(X[col], y)
            if tab.shape == (2, 2) and (tab.values < 5).any():
                _, p = stats.fisher_exact(tab.values)
            else:
                _, p, _, _ = stats.chi2_contingency(tab)
        else:
            p = auto_test_continuous(x0, x1)
        rows.append({
            "variable": col,
            "group": "Clinical" if col in clinical_features else "DSCT",
            "p_value": p
        })
    return pd.DataFrame(rows)

uni_df = univariate_analysis_train(X_train, y_train)
uni_df.to_excel(
    os.path.join(OUTPUT_DIR, "univariate_results_train.xlsx"),
    index=False
)

# ======================================================
# 3b. Significant variables (FOR MODULE 2 – DO NOT DELETE)
# ======================================================
sig_clinical = uni_df.query(
    "group == 'Clinical' and p_value < 0.05"
)["variable"].tolist()

sig_dsct = uni_df.query(
    "group == 'DSCT' and p_value < 0.05"
)["variable"].tolist()

# ======================================================
# 4. Table 2 – Clinical characteristics
# ======================================================
def build_table2(X, y, vars_):
    rows = []
    for col in vars_:
        if col in clinical_categorical:
            tab = pd.crosstab(X[col], y)
            _, p, _, _ = stats.chi2_contingency(tab)
        else:
            p = auto_test_continuous(X.loc[y == 0, col], X.loc[y == 1, col])
        rows.append([col, p])
    return pd.DataFrame(rows, columns=["Variable", "P value"])

build_table2(X_all, y_all, clinical_features).to_excel(
    os.path.join(OUTPUT_DIR, "Table2_Clinical.xlsx"), index=False
)

# ======================================================
# 5. Table 3 – DSCT parameters (AP + VP, journal format)
# ======================================================
def is_normal(x):
    return len(x) >= 3 and stats.shapiro(x)[1] >= 0.05

def summary_normal(x):
    return f"{x.mean():.1f} ± {x.std():.1f}"

def summary_nonnormal(x):
    return f"{x.median():.3f} ({x.min():.3f}, {x.max():.3f})"

def format_p(p):
    return "<0.001" if p < 0.001 else f"{p:.3f}"

def analyze_dsct(var):
    x_all = X_all[var].dropna()
    x0 = X_all.loc[y_all == 0, var].dropna()
    x1 = X_all.loc[y_all == 1, var].dropna()

    normal = is_normal(x0) and is_normal(x1)

    if normal:
        stat, p = stats.ttest_ind(x0, x1, equal_var=False)
        total = summary_normal(x_all)
        benign = summary_normal(x0)
        malignant = summary_normal(x1)
        stat_val = f"{stat:.3f}"
    else:
        stat, p = stats.mannwhitneyu(x0, x1, alternative="two-sided")
        total = summary_nonnormal(x_all)
        benign = summary_nonnormal(x0)
        malignant = summary_nonnormal(x1)
        stat_val = f"{stat:.3f}"

    return total, benign, malignant, stat_val, format_p(p)

rows = []
rows.append(["AP", "", "", "", "", ""])
for v in arterial_vars:
    rows.append([v, *analyze_dsct(v)])

rows.append(["VP", "", "", "", "", ""])
for v in venous_vars:
    rows.append([v, *analyze_dsct(v)])

table3 = pd.DataFrame(
    rows,
    columns=[
        "Variable",
        f"Total (N={len(y_all)})",
        f"Benign (N={(y_all==0).sum()})",
        f"Malignant (N={(y_all==1).sum()})",
        "F-value / Z-value",
        "P-value"
    ]
)

table3.to_excel(
    os.path.join(OUTPUT_DIR, "Table3_DSCT_Parameters.xlsx"),
    index=False
)

# ======================================================
# 6. Table S2–S4: Univariable ROC
# ======================================================
def roc_with_ci(y, s, n_boot=2000):
    rng = np.random.RandomState(RANDOM_STATE)
    aucs = []
    for _ in range(n_boot):
        idx = rng.randint(0, len(s), len(s))
        if len(np.unique(y.iloc[idx])) < 2:
            continue
        aucs.append(roc_auc_score(y.iloc[idx], s.iloc[idx]))
    auc = roc_auc_score(y, s)
    return auc, np.percentile(aucs, 2.5), np.percentile(aucs, 97.5)

def best_cutoff(y, s):
    fpr, tpr, thr = roc_curve(y, s)
    idx = np.argmax(tpr - fpr)
    return tpr[idx], 1 - fpr[idx], thr[idx]

def build_auc_table(vars_, filename):
    rows = []
    for v in vars_:
        s = X_all[v].astype(float)
        auc, lo, hi = roc_with_ci(y_all, s)
        sen, spe, cut = best_cutoff(y_all, s)
        rows.append([v, f"{auc:.3f} ({lo:.3f}-{hi:.3f})", sen, spe, cut])
    pd.DataFrame(
        rows,
        columns=["Variable", "AUC (95% CI)", "Sensitivity", "Specificity", "Cutoff"]
    ).to_excel(os.path.join(OUTPUT_DIR, filename), index=False)

build_auc_table(clinical_features, "Table_S2_Clinical_Performance.xlsx")
build_auc_table(arterial_vars, "Table_S3_Arterial_DSCT_Performance.xlsx")
build_auc_table(venous_vars, "Table_S4_Venous_DSCT_Performance.xlsx")

# ======================================================
# 7. ROC curves
# ======================================================
def plot_multi_roc(X, y, vars_, title, fname):
    plt.figure(figsize=(6, 6), dpi=600)
    for v in vars_:
        s = X[v].astype(float)
        fpr, tpr, _ = roc_curve(y, s)
        auc = roc_auc_score(y, s)
        plt.plot(fpr, tpr, lw=2, label=f"{v} (AUC={auc:.3f})")
    plt.plot([0, 1], [0, 1], '--', color='gray')
    plt.xlabel("1 - Specificity")
    plt.ylabel("Sensitivity")
    plt.title(title)
    plt.legend(fontsize=8, frameon=False)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, fname), dpi=600)
    plt.close()

plot_multi_roc(X_all, y_all, clinical_features, "Clinical", "ROC_Clinical.tiff")
plot_multi_roc(X_all, y_all, arterial_vars, "AP", "ROC_DSCT_Arterial.tiff")
plot_multi_roc(X_all, y_all, venous_vars, "VP", "ROC_DSCT_Venous.tiff")

print("\n===== MODULE 1 COMPLETED (FINAL & MODULE-2-READY) =====")


# 模块 2 —— 共线性分析 + LASSO 特征筛选（Clinical / DSCT / Hybrid）
# （FINAL INTEGRATED VERSION, SAFE & REVIEWER-READY）
# ======================================================

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LassoCV, lasso_path
from statsmodels.stats.outliers_influence import variance_inflation_factor
import matplotlib.pyplot as plt
import seaborn as sns

# ------------------------------------------------------
# Thresholds
# ------------------------------------------------------
PEARSON_TRAIN_THR = 0.70
PEARSON_HYB_THR   = 0.70
VIF_THR           = 5.0

# ------------------------------------------------------
# p_map from univariate analysis (fallback use)
# ------------------------------------------------------
p_map = {row["variable"]: row["p_value"] for _, row in uni_df.iterrows()}

# ======================================================
# 1. Collinearity tools
# ======================================================

def pearson_filter(X_block, thr=0.70, block_name=""):
    X_work = X_block.copy()
    while True:
        if X_work.shape[1] <= 1:
            break
        corr = X_work.corr().abs()
        np.fill_diagonal(corr.values, 0)
        max_corr = corr.max().max()
        if max_corr <= thr:
            break
        i, j = np.where(corr == max_corr)
        col_drop = corr.columns[j[0]]
        print(f"[{block_name}-Pearson] Drop '{col_drop}' | max|r|={max_corr:.3f}")
        X_work = X_work.drop(columns=[col_drop])
    return X_work.columns.tolist()


def vif_filter(X_block, thr=5.0, block_name=""):
    X_work = X_block.copy()
    while True:
        if X_work.shape[1] <= 1:
            break
        Xv = X_work.values
        vifs = [variance_inflation_factor(Xv, i) for i in range(Xv.shape[1])]
        vif_series = pd.Series(vifs, index=X_work.columns)
        max_vif = vif_series.max()
        if max_vif <= thr:
            break
        col_drop = vif_series.idxmax()
        print(f"[{block_name}-VIF] Drop '{col_drop}' | VIF={max_vif:.3f}")
        X_work = X_work.drop(columns=[col_drop])
    return X_work.columns.tolist()


def plot_corr_heatmap(X_block, block_name):
    if X_block.shape[1] <= 1:
        return
    corr = X_block.corr()
    mask = np.triu(np.ones_like(corr, dtype=bool), k=1)
    plt.figure(figsize=(4 + 0.4*corr.shape[1], 4 + 0.4*corr.shape[1]), dpi=600)
    sns.heatmap(
        corr, mask=mask, annot=True, fmt=".2f",
        cmap="RdBu_r", vmin=-1, vmax=1,
        square=True, linewidths=0.5, linecolor="white"
    )
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/Pearson_{block_name}.tiff", dpi=600, bbox_inches="tight")
    plt.close()


def plot_vif_bar(X_block, block_name):
    if X_block.shape[1] == 0:
        return
    Xv = X_block.values
    vifs = [variance_inflation_factor(Xv, i) for i in range(Xv.shape[1])]
    vif_series = pd.Series(vifs, index=X_block.columns).sort_values()
    plt.figure(figsize=(6, 0.5*len(vif_series)+2), dpi=600)
    plt.barh(vif_series.index, vif_series.values)
    plt.xlabel("VIF")
    plt.title("Variance Inflation Factor (VIF) of Features")
    plt.grid(axis="x", alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/VIF_{block_name}.tiff", dpi=600, bbox_inches="tight")
    plt.close()

# ======================================================
# 2. LASSO (CV + coefficient paths)
# ======================================================

def plot_lasso_cv_and_path(X_scaled, y, lasso_cv, block_name):
    alphas = lasso_cv.alphas_
    mse_path = lasso_cv.mse_path_
    mean_mse = mse_path.mean(axis=1)
    std_mse  = mse_path.std(axis=1)

    idx_min = np.argmin(mean_mse)
    alpha_min = alphas[idx_min]
    idx_1se = np.where(mean_mse <= mean_mse[idx_min] + std_mse[idx_min])[0][-1]
    alpha_1se = alphas[idx_1se]

    # CV curve
    plt.figure(figsize=(6,5), dpi=300)
    plt.errorbar(np.log10(alphas), mean_mse, yerr=std_mse, fmt='-o', markersize=3)
    plt.axvline(np.log10(alpha_min), color='red', linestyle='--', label=r'$\lambda_{min}$')
    plt.axvline(np.log10(alpha_1se), color='blue', linestyle='--', label=r'$\lambda_{1se}$')
    plt.xlabel("log10(lambda)")
    plt.ylabel("Mean CV MSE")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.savefig(f"{OUTPUT_DIR}/LASSO_CV_{block_name}.tiff", dpi=600, bbox_inches="tight")
    plt.close()

    # Coefficient paths
    alphas_lasso, coefs_lasso, _ = lasso_path(X_scaled, y, alphas=alphas)
    plt.figure(figsize=(6,5), dpi=300)
    for i in range(coefs_lasso.shape[0]):
        plt.plot(np.log10(alphas_lasso), coefs_lasso[i, :], linestyle='--')
    plt.axvline(np.log10(alpha_min), color='red', linestyle='--')
    plt.axvline(np.log10(alpha_1se), color='blue', linestyle='--')
    plt.xlabel("log10(lambda)")
    plt.ylabel("Coefficients")
    plt.grid(alpha=0.3)
    plt.savefig(f"{OUTPUT_DIR}/LASSO_Path_{block_name}.tiff", dpi=600, bbox_inches="tight")
    plt.close()

    return alpha_min, alpha_1se


def lasso_select_numeric_block(X_block, y_block, block_name, p_map_block, cv_folds=5):
    if X_block.shape[1] == 0:
        return []
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_block.values)
    lasso_cv = LassoCV(cv=cv_folds, random_state=RANDOM_STATE)
    lasso_cv.fit(X_scaled, y_block.values)
    _, alpha_1se = plot_lasso_cv_and_path(
        X_scaled, y_block.values, lasso_cv, block_name
    )
    lasso_final = LassoCV(alphas=[alpha_1se], cv=cv_folds, random_state=RANDOM_STATE)
    lasso_final.fit(X_scaled, y_block.values)
    coef = pd.Series(lasso_final.coef_, index=X_block.columns)
    selected = coef[coef != 0].index.tolist()
    if len(selected) == 0:
        selected = [min(X_block.columns, key=lambda v: p_map_block.get(v, 1.0))]
    return selected

# ======================================================
# 3. DSCT block
# ======================================================
dsct_final_vars = []
if len(sig_dsct) > 0:
    X_dsct_tr0 = X_train[sig_dsct].copy()
    plot_corr_heatmap(X_dsct_tr0, "DSCT")
    plot_vif_bar(X_dsct_tr0, "DSCT")

    keep_p = pearson_filter(X_dsct_tr0, PEARSON_TRAIN_THR, "DSCT")
    X_dsct_p = X_dsct_tr0[keep_p]

    keep_v = vif_filter(X_dsct_p, VIF_THR, "DSCT")
    X_dsct_final_for_lasso = X_dsct_p[keep_v]

    p_map_dsct = {v: p_map.get(v, 1.0) for v in X_dsct_final_for_lasso.columns}
    dsct_final_vars = lasso_select_numeric_block(
        X_dsct_final_for_lasso, y_train, "DSCT", p_map_dsct
    )

# ======================================================
# 4. Clinical block
# ======================================================
clin_final_vars = []
if len(sig_clinical) > 0:
    X_clin_tr0 = X_train[sig_clinical].copy()
    X_clin_tr0 = X_clin_tr0.select_dtypes(include=[np.number])

    plot_corr_heatmap(X_clin_tr0, "Clinical")
    plot_vif_bar(X_clin_tr0, "Clinical")

    keep_p = pearson_filter(X_clin_tr0, PEARSON_TRAIN_THR, "Clinical")
    X_clin_p = X_clin_tr0[keep_p]

    keep_v = vif_filter(X_clin_p, VIF_THR, "Clinical")
    X_clin_final_for_lasso = X_clin_p[keep_v]

    p_map_clin = {v: p_map.get(v, 1.0) for v in X_clin_final_for_lasso.columns}
    clin_final_vars = lasso_select_numeric_block(
        X_clin_final_for_lasso, y_train, "Clinical", p_map_clin
    )

# ======================================================
# 5. Hybrid block
# ======================================================
hybrid_final_vars = []   # ✅ 防御式初始化（修复 NameError）

hybrid_candidates = sorted(list(set(clin_final_vars + dsct_final_vars)))
if len(hybrid_candidates) > 0:
    X_hyb_tr0 = X_train[hybrid_candidates].copy()
    plot_corr_heatmap(X_hyb_tr0, "Hybrid")
    plot_vif_bar(X_hyb_tr0, "Hybrid")

    keep_h = pearson_filter(X_hyb_tr0, PEARSON_HYB_THR, "Hybrid")
    X_hyb_for_lasso = X_hyb_tr0[keep_h]

    p_map_hyb = {v: p_map.get(v, 1.0) for v in X_hyb_for_lasso.columns}
    hybrid_final_vars = lasso_select_numeric_block(
        X_hyb_for_lasso, y_train, "Hybrid", p_map_hyb
    )

# ======================================================
# 6. Save selected variables
# ======================================================
pd.DataFrame({"Clinical_LASSO": clin_final_vars}).to_csv(
    f"{OUTPUT_DIR}/Clinical_LASSO_selected_vars.csv", index=False
)
pd.DataFrame({"DSCT_LASSO": dsct_final_vars}).to_csv(
    f"{OUTPUT_DIR}/DSCT_LASSO_selected_vars.csv", index=False
)
pd.DataFrame({"Hybrid_LASSO": hybrid_final_vars}).to_csv(
    f"{OUTPUT_DIR}/Hybrid_LASSO_selected_vars.csv", index=False
)

# ======================================================
# 7. Supplementary Tables S5–S9
# ======================================================

def save_pearson_table(X, fn):
    X.corr().round(3).to_excel(f"{OUTPUT_DIR}/{fn}")

def save_vif_table(X, fn):
    rows = [[c, variance_inflation_factor(X.values, i)] for i,c in enumerate(X.columns)]
    pd.DataFrame(rows, columns=["Variable","VIF"]).to_excel(
        f"{OUTPUT_DIR}/{fn}", index=False
    )

def save_cross_pearson(row_vars, col_vars, X, fn):
    corr = pd.DataFrame(index=row_vars, columns=col_vars)
    for r in row_vars:
        for c in col_vars:
            corr.loc[r,c] = X[r].corr(X[c])
    corr.round(3).to_excel(f"{OUTPUT_DIR}/{fn}")

clinical_corr_vars = [
    "Tumor size (mm)",
    "Shape",
    "Margin",
    "Enhancement degree",
    "Enhancement pattern"
]

arterial_vars = ["A40","A70","AλHU","A100","AIC","AZeff","ANIC","ANZeff"]
venous_vars   = ["V40","V70","VλHU","V100","VIC","VZeff","VNIC","VNZeff"]
dsct_all_vars = arterial_vars + venous_vars

save_pearson_table(X_train[clinical_corr_vars], "Table_S5_Clinical_Pearson.xlsx")
save_vif_table(X_train[clinical_corr_vars], "Table_S6_Clinical_VIF.xlsx")
save_cross_pearson(dsct_all_vars, arterial_vars, X_train, "Table_S7a_All_vs_Arterial_DSCT_Pearson.xlsx")
save_cross_pearson(dsct_all_vars, venous_vars,  X_train, "Table_S7b_All_vs_Venous_DSCT_Pearson.xlsx")
save_vif_table(X_train[dsct_all_vars], "Table_S8_All_DSCT_VIF.xlsx")

if len(hybrid_final_vars) > 1:
    save_pearson_table(X_train[hybrid_final_vars], "Table_S9_Hybrid_Pearson.xlsx")

print("\n===== MODULE 2 COMPLETED (FINAL, SAFE VERSION) =====")


# ======================================================
# ======================================================
# MODULE 3 – Final Journal-grade Evaluation
#   • Nested CV (AUC only, robustness)
#   • 3-model ROC / Calibration / DCA (Train / Val / Test)
#   • UPDATED: AUC (95% CI) + Cutoff value (Youden index)
# ======================================================

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl

from scipy import stats
from scipy.signal import savgol_filter
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, roc_curve,
    accuracy_score, recall_score, matthews_corrcoef
)
from statsmodels.nonparametric.smoothers_lowess import lowess
from scipy.stats import chi2

# ------------------------------------------------------
# Global style (journal-safe)
# ------------------------------------------------------
mpl.rcParams["font.family"] = "Times New Roman"
mpl.rcParams.update({
    "axes.labelsize": 12,
    "xtick.labelsize": 11,
    "ytick.labelsize": 11,
    "legend.fontsize": 11
})

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ------------------------------------------------------
# Global CV settings (UNCHANGED)
# ------------------------------------------------------
N_OUTER = 5
N_INNER = 5
P_UNI = 0.05
PEARSON_THR = 0.7

# ======================================================
# 0. Shared utilities (UNCHANGED)
# ======================================================
def build_logistic():
    return Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(
            max_iter=3000,
            solver="liblinear"
        ))
    ])

def safe_univariate_filter(X, y, p_thresh=0.05):
    keep = []
    for col in X.columns:
        try:
            if X[col].nunique() <= 3:
                tab = pd.crosstab(X[col], y)
                if tab.shape[0] < 2 or tab.shape[1] < 2:
                    continue
                _, p, _, _ = stats.chi2_contingency(tab)
            else:
                x0 = X.loc[y == 0, col]
                x1 = X.loc[y == 1, col]
                if len(x0) < 3 or len(x1) < 3:
                    continue
                _, p = stats.ttest_ind(x0, x1, equal_var=False)

            if np.isfinite(p) and p < p_thresh:
                keep.append(col)
        except Exception:
            continue
    return keep


def safe_pearson_filter(X, thr=0.7):
    cols = list(X.columns)
    while len(cols) > 1:
        corr = X[cols].corr().abs()
        np.fill_diagonal(corr.values, 0)
        if corr.max().max() <= thr:
            break
        drop_col = corr.stack().idxmax()[1]
        cols.remove(drop_col)
    return cols


def safe_lasso_1se(X, y):
    scaler = StandardScaler()
    Xs = scaler.fit_transform(X)

    lasso = LassoCV(cv=N_INNER, random_state=RANDOM_STATE)
    lasso.fit(Xs, y)

    mse_mean = lasso.mse_path_.mean(axis=1)
    mse_std  = lasso.mse_path_.std(axis=1)
    idx_min  = np.argmin(mse_mean)
    idx_1se  = np.where(mse_mean <= mse_mean[idx_min] + mse_std[idx_min])[0][-1]

    alpha_1se = lasso.alphas_[idx_1se]

    lasso_final = LassoCV(
        alphas=[alpha_1se],
        cv=N_INNER,
        random_state=RANDOM_STATE
    )
    lasso_final.fit(Xs, y)

    coef = pd.Series(lasso_final.coef_, index=X.columns)
    feats = coef[coef != 0].index.tolist()

    if len(feats) == 0:
        feats = [coef.abs().idxmax()]

    return feats

# ======================================================
# 1. Nested CV (AUC only, UNCHANGED)
# ======================================================
def run_nested_cv_auc_only(X, y, model_name):
    outer_cv = StratifiedKFold(
        n_splits=N_OUTER,
        shuffle=True,
        random_state=RANDOM_STATE
    )

    aucs = []
    n_total = 0
    n_valid = 0

    for tr_idx, te_idx in outer_cv.split(X, y):
        n_total += 1

        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]
        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]

        sig_feats = safe_univariate_filter(X_tr, y_tr, P_UNI)
        if len(sig_feats) == 0:
            continue

        X_sig = X_tr[sig_feats]
        X_sig = X_sig[safe_pearson_filter(X_sig, PEARSON_THR)]

        feats = safe_lasso_1se(X_sig, y_tr)
        if len(feats) == 0:
            continue

        model = build_logistic()
        model.fit(X_tr[feats], y_tr)

        prob = model.predict_proba(X_te[feats])[:, 1]
        aucs.append(roc_auc_score(y_te, prob))
        n_valid += 1

    print(f"[Nested CV] {model_name}: valid folds {n_valid}/{n_total}")
    return np.mean(aucs), np.std(aucs)

# ======================================================
# 2. UPDATED performance utilities (NEW)
# ======================================================
def auc_with_ci(y_true, prob, n_boot=2000):
    rng = np.random.RandomState(RANDOM_STATE)
    y_true = np.asarray(y_true)
    prob = np.asarray(prob)

    aucs = []
    for _ in range(n_boot):
        idx = rng.randint(0, len(prob), len(prob))
        if len(np.unique(y_true[idx])) < 2:
            continue
        aucs.append(roc_auc_score(y_true[idx], prob[idx]))

    auc = roc_auc_score(y_true, prob)
    lo = np.percentile(aucs, 2.5)
    hi = np.percentile(aucs, 97.5)
    return auc, lo, hi


def youden_cutoff(y_true, prob):
    fpr, tpr, thresholds = roc_curve(y_true, prob)
    youden = tpr - fpr
    idx = np.argmax(youden)
    cutoff = thresholds[idx]
    sens = tpr[idx]
    spec = 1 - fpr[idx]
    return cutoff, sens, spec

# ======================================================
# 3. UPDATED fixed-model evaluation (ONLY change here)
# ======================================================
def evaluate_and_predict(name, X_tr, y_tr, X_te, y_te):
    model = build_logistic()
    model.fit(X_tr, y_tr)

    prob = model.predict_proba(X_te)[:, 1]

    auc, lo, hi = auc_with_ci(y_te, prob)
    cutoff, sen, spe = youden_cutoff(y_te, prob)

    pred = (prob >= cutoff).astype(int)
    acc = accuracy_score(y_te, pred)
    mcc = matthews_corrcoef(y_te, pred)

    return prob, (
        f"{auc:.3f} ({lo:.3f}–{hi:.3f})",
        sen, spe, acc, mcc, cutoff
    )

# ======================================================
# 4. Run evaluation (LOGIC UNCHANGED)
# ======================================================
train_probs, val_probs, test_probs = {}, {}, {}
perf_rows = []

model_blocks = {
    "Clinico-radiological": clin_final_vars,
    "DSCT-based": dsct_final_vars,
    "Hybrid": hybrid_final_vars
}

for name, feats in model_blocks.items():
    p_tr, m_tr = evaluate_and_predict(
        name, X_train[feats], y_train, X_train[feats], y_train
    )
    p_val, m_val = evaluate_and_predict(
        name, X_train[feats], y_train, X_val[feats], y_val
    )
    p_te, m_te = evaluate_and_predict(
        name, X_train[feats], y_train, X_test[feats], y_test
    )

    train_probs[name] = p_tr
    val_probs[name]   = p_val
    test_probs[name]  = p_te

    perf_rows += [
        [name, "Train (apparent)", *m_tr],
        [name, "Val", *m_val],
        [name, "Test", *m_te],
    ]

pd.DataFrame(
    perf_rows,
    columns=[
        "Model", "Set",
        "AUC (95% CI)",
        "Sensitivity", "Specificity",
        "Accuracy", "MCC",
        "Cutoff value"
    ]
).to_csv(
    f"{OUTPUT_DIR}/Model_Performance_TrainValTest.csv",
    index=False
)

# ======================================================
# 3. Plotting (ROC / Calibration / DCA with a,b,c labels)
# ======================================================
colors = {
    "Clinico-radiological": "tab:blue",
    "DSCT-based": "tab:orange",
    "Hybrid": "tab:green"
}

# ---------- ROC ----------
def plot_roc_panel(ax, y_true, prob_dict):
    for name, prob in prob_dict.items():
        fpr, tpr, _ = roc_curve(y_true, prob)
        auc_ = roc_auc_score(y_true, prob)
        ax.plot(fpr, tpr, lw=2.2, color=colors[name],
                label=f"{name} (AUC={auc_:.3f})")
    ax.plot([0, 1], [0, 1], "--", color="gray")
    ax.set_xlabel("1 − Specificity")
    ax.set_ylabel("Sensitivity")
    ax.grid(alpha=0.3)
    ax.legend(frameon=False)

# ---------- Calibration ----------
def hosmer_lemeshow_test(y_true, prob, g=10):
    data = np.vstack([prob, y_true]).T
    data = data[np.argsort(data[:, 0])]
    bins = np.array_split(data, g)

    hl = 0
    for b in bins:
        obs1 = b[:, 1].sum()
        exp1 = b[:, 0].sum()
        n = len(b)
        obs0 = n - obs1
        exp0 = n - exp1
        hl += (obs1-exp1)**2/(exp1+1e-8) + (obs0-exp0)**2/(exp0+1e-8)

    return hl, 1 - chi2.cdf(hl, g-2)

def grouped_calibration(prob, y_true, g, mode):
    data = np.vstack([prob, y_true]).T
    data = data[np.argsort(data[:, 0])]
    bins = np.array_split(data, g)
    mp = np.array([b[:,0].mean() for b in bins])
    mo = np.array([b[:,1].mean() for b in bins])

    frac = 0.55 if mode=="train" else 0.75
    sm = lowess(mo, mp, frac=frac, return_sorted=True)
    sm = np.vstack([[0,0], sm])
    return sm[:,0], sm[:,1]

def plot_calibration_panel(ax, y_true, prob_dict, g, mode):
    for name, prob in prob_dict.items():
        xs, ys = grouped_calibration(prob, y_true, g, mode)
        ax.plot(xs, ys, lw=2.5, color=colors[name], label=name)
    ax.plot([0,1],[0,1],"--",color="black",label="Ideal")
    ax.set_xlabel("Predicted probability")
    ax.set_ylabel("Observed probability")
    ax.grid(alpha=0.3)
    ax.legend(frameon=False)

# ---------- DCA ----------
def compute_nb(y, prob, pts):
    y = np.asarray(y)
    prob = np.asarray(prob)
    n = len(y)
    out = []
    for pt in pts:
        pred = prob >= pt
        TP = ((pred==1)&(y==1)).sum()
        FP = ((pred==1)&(y==0)).sum()
        out.append(TP/n - FP/n * pt/(1-pt))
    return np.array(out)

def plot_dca_panel(ax, y_true, prob_dict):
    pts = np.linspace(0.1, 0.9, 400)
    prev = y_true.mean()

    ax.plot(pts, np.zeros_like(pts), "--", color="gray", label="Treat-none")
    ta = prev - (1-prev)*pts/(1-pts)
    ta_s = lowess(ta, pts, frac=0.1)
    ax.plot(ta_s[:,0], ta_s[:,1], ":", color="black", label="Treat-all")

    for name, prob in prob_dict.items():
        nb = compute_nb(y_true, prob, pts)
        nb_s = lowess(nb, pts, frac=0.12)
        nb_s = savgol_filter(nb_s[:,1], 41, 3)
        ax.plot(pts, nb_s, lw=2.2, color=colors[name], label=name)

    ax.set_xlabel("Threshold probability")
    ax.set_ylabel("Net benefit")
    ax.grid(alpha=0.3)
    ax.legend(frameon=False)

# ======================================================
# 4. Generate figures (a,b,c)
# ======================================================
def generate_all_figures():

    # ROC
    fig, ax = plt.subplots(1,3,figsize=(22,6),dpi=600)
    plot_roc_panel(ax[0], y_train, train_probs)
    plot_roc_panel(ax[1], y_val,   val_probs)
    plot_roc_panel(ax[2], y_test,  test_probs)
    for i,a in enumerate(ax):
        a.text(-0.15,1.08,chr(97+i),transform=a.transAxes,
               fontsize=28,fontweight="bold")
    fig.savefig(f"{OUTPUT_DIR}/ROC_3models_3sets.tiff",
                dpi=600,bbox_inches="tight")
    plt.close()

    # Calibration
    fig, ax = plt.subplots(1,3,figsize=(22,6),dpi=600)
    plot_calibration_panel(ax[0], y_train, train_probs, g=6, mode="train")
    plot_calibration_panel(ax[1], y_val,   val_probs,   g=3, mode="test")
    plot_calibration_panel(ax[2], y_test,  test_probs,  g=3, mode="test")
    for i,a in enumerate(ax):
        a.text(-0.15,1.08,chr(97+i),transform=a.transAxes,
               fontsize=28,fontweight="bold")
    fig.savefig(f"{OUTPUT_DIR}/Calibration_3models_3sets.tiff",
                dpi=600,bbox_inches="tight")
    plt.close()

    # DCA
    fig, ax = plt.subplots(1,3,figsize=(22,6),dpi=600)
    plot_dca_panel(ax[0], y_train, train_probs)
    plot_dca_panel(ax[1], y_val,   val_probs)
    plot_dca_panel(ax[2], y_test,  test_probs)
    for i,a in enumerate(ax):
        a.text(-0.15,1.08,chr(97+i),transform=a.transAxes,
               fontsize=28,fontweight="bold")
    fig.savefig(f"{OUTPUT_DIR}/DCA_3models_3sets.tiff",
                dpi=600,bbox_inches="tight")
    plt.close()

generate_all_figures()

print("\n===== MODULE 3 COMPLETED (Reviewer-safe & Journal-ready) =====")

# ======================================================
# MODULE 4 – Final Hybrid Nomogram Formula
# (Based strictly on final LASSO-selected hybrid features)
# ======================================================

import os
import pandas as pd
from sklearn.linear_model import LogisticRegression

# ------------------------------------------------------
# 1. Load full dataset (for final nomogram only)
# ------------------------------------------------------
df = pd.read_excel(DATA_PATH)

# ===== BUG FIX 1: 与 MODULE 1 保持列名一致 =====
df = df.rename(columns={"Tumor size": "Tumor size (mm)"})

# Outcome
y = df[TARGET_COL].astype(int)

# ------------------------------------------------------
# 2. Sanity check: Nomogram variables must come from Hybrid LASSO
# ------------------------------------------------------
# （不改变任何结果，仅防 reviewer 质疑“模型不一致”）
assert set([
    "Tumor size (mm)",
    "VNZeff"
]).issubset(set(hybrid_final_vars)), \
    "Nomogram continuous variables are not from Hybrid LASSO selection"

# ------------------------------------------------------
# 3. Explicit dummy coding (REFERENCE LEVELS FIXED)
# ------------------------------------------------------
X = pd.DataFrame(index=df.index)

# ----- Shape (reference = Regular = 0) -----
X["Shape (Irregular)"] = (df["Shape"] == 1).astype(int)

# ----- Enhancement degree (reference = Light = 0) -----
X["Enhancement degree (Moderate)"] = (df["Enhancement degree"] == 1).astype(int)
X["Enhancement degree (Marked)"]   = (df["Enhancement degree"] == 2).astype(int)

# ----- Margin (reference = Circumscribed = 0) -----
X["Margin (Irregular)"]  = (df["Margin"] == 1).astype(int)
X["Margin (Spiculated)"] = (df["Margin"] == 2).astype(int)

# ----- Continuous variables -----
X["Tumor size (mm)"] = df["Tumor size (mm)"].astype(float)
X["VNZeff"]          = df["VNZeff"].astype(float)

# Drop missing values (keep alignment)
X = X.loc[~X.isna().any(axis=1)]
y = y.loc[X.index]

# ------------------------------------------------------
# 4. Fit final logistic regression (interpretability model)
# ------------------------------------------------------
logit = LogisticRegression(
    penalty="l2",
    solver="liblinear",
    max_iter=5000
)
logit.fit(X, y)

# ------------------------------------------------------
# 5. Extract coefficients
# ------------------------------------------------------
intercept = logit.intercept_[0]
coef = pd.Series(logit.coef_[0], index=X.columns)

# ------------------------------------------------------
# 6. Generate manuscript-ready formula
# ------------------------------------------------------
print("\n================ FINAL HYBRID NOMOGRAM FORMULA ================\n")

formula = (
    "Hybrid nomogram = log( P(Malignant) / P(Benign) ) = "
    f"{intercept:.4f}"
)

for var, beta in coef.items():
    formula += f" + {beta:.4f} × {var}"

print(formula)

# ------------------------------------------------------
# 7. Save coefficient table (Supplementary Material)
# ------------------------------------------------------
coef_table = pd.DataFrame({
    "Variable": list(coef.index) + ["Intercept"],
    "Coefficient (logit β)": list(coef.values) + [intercept]
})

coef_table.to_csv(
    os.path.join(OUTPUT_DIR, "Hybrid_Nomogram_Coefficients_Final.csv"),
    index=False
)

print("\nCoefficient table saved: Hybrid_Nomogram_Coefficients_Final.csv")

